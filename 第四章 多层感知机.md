## 4.1 多层感知机
多层感知机是最简单的深度神经网络

## 4.1.1 隐藏层

线性模型的假设在实际中常不成立。为解决此问题，我们在网络中加入隐藏层。它将多个全连接层堆叠在一起，以前 $L-1$ 层看作表示，最后一层看作线性预测器，这种架构就是**多层感知机 (mulilayer perceptron, MLP)**
![[Pasted image 20250316224206.png]]

以 $\textbf{X} \in \mathbb{R}^{n \times d}$ 表示 $n$ 个样本小批量，$d$ 表示输入特征数；对于 $h$ 个隐藏单元的单隐藏层多层感知机，$\textbf{H} \in \mathbb{R}^{n \times d}$ 表示隐藏层输出，称为**隐藏表示(hidden representation)**，又称为**隐藏变量 (hidden variable)**。在全连接情况下，隐藏层权重 $\textbf{W}^{(1)} \in \mathbb{R}^{d \times h}$，偏置 $\textbf{b}^{(1)} \in \mathbb{R}^{1 \times h}$，输出层权重 $\textbf{W}^{(2)} \in \mathbb{R}^{h \times q}$，偏置 $\textbf{b}^{(2)} \in \mathbb{R}^{1 \times q}$。计算输出 $\textbf{O} \in \mathbb{R}^{n \times q}$：
$$
\begin{aligned}
\mathbf{H}=\mathbf{X}\mathbf{W}^{(1)}+\mathbf{b}^{(1)}\\\mathbf{O}=\mathbf{H}\mathbf{W}^{(2)}+\mathbf{b}^{(2)}
\end{aligned}
$$
这种简单的计算方式与单层神经网络无异，因为：
$$
\mathbf{O}=(\mathbf{X}\mathbf{W}^{(1)}+\mathbf{b}^{(1)})\mathbf{W}^{(2)}+\mathbf{b}^{(2)}=\mathbf{X}\mathbf{W}^{(1)}\mathbf{W}^{(2)}+\mathbf{b}^{(1)}\mathbf{W}^{(2)}+\mathbf{b}^{(2)}=\mathbf{X}\mathbf{W}+\mathbf{b}.
$$
所以我们在仿射变换后需要对每个隐藏单元应用非线性的**激活函数 (activation function)**$\sigma$，它的输出称为**活性值(activations)**：
$$
\begin{aligned}
 & \mathbf{H}=\sigma(\mathbf{XW}^{(1)}+\mathbf{b}^{(1)}), \\
 & \mathbf{O}=\mathbf{HW}^{(2)}+\mathbf{b}^{(2)}
\end{aligned}
$$
这里的 $\sigma$ 既可以按行 (按样本) 对 $\textbf{X}$ 操作，也可按元素操作。这意味着每个活性值的计算独立，不需要查看其他隐藏单元所取的值。堆叠更多的层，我们可以逼近许多函数

### 4.1.2 激活函数
激活函数通过计算加权和并加上偏置确定神经元是否应该激活，下面介绍部分激活函数

**ReLU 函数**
**修正线性单元 (Rectified linear unit, ReLU)** 形式如下：
$$
\text{ReLU}  (x) = \max(x, 0)
$$
即将活性值保留为正数或 0，丢弃所有的负数，该函数的图像和导数图像如下：
```python
import torch  
from d2l import torch as d2l  
import matplotlib.pyplot as plt  
  
x = torch.arange(-8.0, 8.0, 0.1, requires_grad=True)  
y = torch.relu(x)  
fig, ax = plt.subplots(2, 1)  
ax[0].plot(x.detach().numpy(), y.detach().numpy(), 'x', 'ReLU(x)',  
           marker='.')  
  
y.backward(torch.ones_like(x), retain_graph=True)  
ax[1].plot(x.detach().numpy(), x.grad.numpy(), 'x', 'Grad',  
           marker='.')  
  
plt.show()
```
![[Pasted image 20250316231139.png]] ReLU 在输入为正时导数为 1，其余为 0。ReLU 减轻了梯度消失问题，其中的一个变体是 pReLU：
$$
\text{pReLU} (x) = \max(0, x) + \alpha (0, x)
$$
它在某些参数为负时仍然允许通过

**sigmoid 函数**
**sigmoid 函数**将实数映射到 $(0, 1)$ 上，被称为**挤压函数 (squashing function)**:
$$
\mathrm{sigmoid}(x)=\frac{1}{1+\exp(-x)}
$$
sigmoid 函数可视为 softmax 函数的特例，它的函数图像和导数图像如下：
```python
y = torch.sigmoid(x)
d2l.plot(x.detach(), y.detach(), 'x', 'sigmoid(x)', figsize=(5, 2.5))

# 清除以前的梯度
x.grad.data.zero_()
y.backward(torch.ones_like(x),retain_graph=True)
d2l.plot(x.detach(), x.grad, 'x', 'grad of sigmoid', figsize=(5, 2.5))
```
>  注意到输入接近零时，sigmoid 函数接近线性变换


![[Pasted image 20250316232633.png]] ![[Pasted image 20250316232643.png]]
**tanh 函数**
**双曲正切 (tanh)** 函数与 sigmoid 函数类似，也能将输入转换到区间 $(-1, 1)$ 上：
$$
\tanh(x)=\frac{1-\exp(-2x)}{1+\exp(-2x)}
$$
双曲正切有一个特性，它的函数图像关于原点对称。下面画出图像：
```python
with autograd.record():
    y = np.tanh(x)
d2l.plot(x, y, 'x', 'tanh(x)', figsize=(5, 2.5))

y.backward()
d2l.plot(x, x.grad, 'x', 'grad of tanh', figsize=(5, 2.5))
```

## 4.2 多层感知机从零开始实现
下面使用 `Fashion-MNIST` 数据集，实现多层感知机应用：
```python
import torch
from torch import nn
from d2l import torch as d2l

batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
```

### 4.2.1 初始化参数
数据集中的图像大小为 $28 \times 28 = 784$ 个灰度像素值，我们视为 $784$ 个不同的输入特征；共 10 个类别，视为 10 个分类。这里设置单隐藏层，包含 $256$ 个隐藏单元
> 一般选择 $2$ 的 $n$ 次幂作为隐藏层宽度，在计算上更高效

下面用张量表示参数：
```python
#初始化参数
num_inputs, num_outputs, num_hiddens = 784, 10, 256

W1 = nn.Parameter(torch.randn(
    num_inputs, num_hiddens, requires_grad=True) * 0.01) #这里乘以0.01是防止梯度消失/爆炸
b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True)) #偏置项可用0向量
W2 = nn.Parameter(torch.randn(
    num_hiddens, num_outputs, requires_grad=True) * 0.01)
b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True))

params = [W1, b1, W2, b2]
```
这里的 `torch.randn` 生成正态分布张量，需要填入长宽数值；`nn.Parameter` 是一类对象，能将 `Tensor` 包装为能被识别为模型的参数

### 4.2.2 - 4.2.4  激活函数、模型和损失函数
手动实现 ReLU 激活函数：
```python
def relu(X):
    a = torch.zeros_like(X)
    return torch.max(X, a)
```

这里忽略图像空间结构，用 `reshape` 将二维图像转为长度为 `num_inputs` 的向量：
```python
def net(X):
    X = X.reshape((-1, num_inputs))
    H = relu(X@W1 + b1)  # 这里“@”代表矩阵乘法
    return (H@W2 + b2)
```
在[[第三章 线性神经网络]]中已经实现过分类模型的交叉熵损失函数，这里直接调用 API：
```python
loss = nn.CrossEntropyLoss(reduction='none')
```
### 4.2.5 训练
多层感知机的训练过程同 softmax 回归，直接调用 `train_ch3` 函数即可：
```python
#训练模型
num_epochs, lr = 10, 0.1
updater = torch.optim.SGD(params, lr=lr)
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)

#模型测试
d2l.predict_ch3(net, test_iter)
plt.show()
```

## 4.3 多层感知机简洁实现

在 softmax 基础上添加两个全连接层即为 MLP：
```python
import torch
from torch import nn
from d2l import torch as d2l

#定义模型
net = nn.Sequential(nn.Flatten(),
                    nn.Linear(784, 256), #第一层输入-隐藏层
                    nn.ReLU(),
                    nn.Linear(256, 10)) #第二层隐藏层-输出

def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, std=0.01) #自动初始化

net.apply(init_weights)

#应用模型
batch_size, lr, num_epochs = 256, 0.1, 10 #超参数
loss = nn.CrossEntropyLoss(reduction='none') #损失函数
trainer = torch.optim.SGD(net.parameters(), lr=lr) #定义优化器

#训练模型
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)
```
## 4.4 模型选择、欠拟合和过拟合
科学家研究机器学习的目的是发现**模式 (pattern)**，我们不希望模型单纯记住数据集，而不是泛化。将模型在训练数据上拟合的比在潜在分布中更接近的现象称为**过拟合 (overfitting)**, 用于对抗过拟合的技术称为**正则化 (regularization)**

### 4.4.1 训练误差和泛化误差
**训练误差 (training error)** 是指, 模型在训练数据集上计算得到的误差。**泛化误差 (generalization error)** 是指, 模型应用在同样从原始样本的分布中抽取的无限多数据样本时, 模型误差的期望

一般探讨中，假设训练集和测试集满足**独立同分布假设 (i.i.d. assumption)**。现实中的数据不一定满足此假设，但轻微的违反对模型准确性影响不大

具有更多参数的模型可能被认为更复杂, 参数有更大取值范围的模型可能更为复杂。通常对于神经网络,我们认为需要更多训练迭代的模型比较复杂,而需要**早停 (early  stopping)** 的模型 (即较少训练迭代周期) 就不那么复杂

几个影响模型泛化的因素：
1. 可调整参数的数量。当可调整参数的数量 (有时称为自由度) 很大时, 模型往往更容易过拟合
2. 参数采用的值。当权重的取值范围较大时, 模型可能更容易过拟合
3. 训练样本的数量。即使模型很简单,也很容易过拟合只包含一两个样本的数据集。而过拟合一个有数百万个样本的数据集则需要一个极其灵活的模型

### 4.4.2 模型选择
对于训练集、验证集和测试集：
* 训练集，用于训练模型
* **验证集(validation set)**，用于调优参数
* 测试集，用于模拟真实的未见过场景
实际使用中需要避免泄露测试集数据到模型训练过程中
> 原书中无测试集，精度为验证集精度

数据集较小时，可用 $K$ 交叉检验来构成验证集

### 4.4.3-4.4.4 欠拟合、过拟合和多项式回归

多项式回归方程：
$$
\hat y = \sum^d_{i=0} x^i \omega_i
$$
是一个 $d$ 阶多项式，当 $d$ 特别大时，将会产生过拟合；$d$ 很小时，则会欠拟合。可通过实验验证

生成数据满足公式：
$$
y=5+1.2x-3.4\frac{x^2}{2!}+5.6\frac{x^3}{3!}+\epsilon\mathrm{~where~}\epsilon\sim\mathcal{N}(0,0.1^2).
$$
```python
import math
import numpy as np
import torch
from torch import nn
from d2l import torch as d2l

#生成数据集
max_degree = 20  # 多项式的最大阶数
n_train, n_test = 100, 100  # 训练和测试数据集大小
true_w = np.zeros(max_degree)  # 分配大量的空间
true_w[0:4] = np.array([5, 1.2, -3.4, 5.6]) #本次指定最高幂为3

features = np.random.normal(size=(n_train + n_test, 1)) #原始数据x向量
np.random.shuffle(features) #打乱
poly_features = np.power(features, np.arange(max_degree).reshape(1, -1)) #对x计算不同次幂, 生成(200, 20)矩阵
for i in range(max_degree): #控制各项尺度相近
    poly_features[:, i] /= math.gamma(i + 1)  #gamma(n)=(n-1)!
# labels的维度:(n_train+n_test,)
labels = np.dot(poly_features, true_w) #产生观测值y
labels += np.random.normal(scale=0.1, size=labels.shape) #添加噪声
```
将数据转换为 `Tensor` 类型：
```python
# NumPy ndarray转换为tensor
true_w, features, poly_features, labels = [torch.tensor(x, dtype=
    torch.float32) for x in [true_w, features, poly_features, labels]]

print(features[:2], poly_features[:2, :], labels[:2])
```

要对模型进行训练和测试，先定义损失评估：
```python
def evaluate_loss(net, data_iter, loss):  
    """评估给定数据集上模型的损失"""
    metric = d2l.Accumulator(2)  # 损失的总和,样本数量
    for X, y in data_iter:
        out = net(X)
        y = y.reshape(out.shape)
        l = loss(out, y)
        metric.add(l.sum(), l.numel())
    return metric[0] / metric[1]
```
定义训练函数：
```python
def train(train_features, test_features, train_labels, test_labels,
          num_epochs=400):
    loss = nn.MSELoss(reduction='none')
    input_shape = train_features.shape[-1]
    # 不设置偏置，因为我们已经在多项式中实现了它
    net = nn.Sequential(nn.Linear(input_shape, 1, bias=False))
    batch_size = min(10, train_labels.shape[0])
    train_iter = d2l.load_array((train_features, train_labels.reshape(-1,1)),
                                batch_size)
    test_iter = d2l.load_array((test_features, test_labels.reshape(-1,1)),
                               batch_size, is_train=False)
    trainer = torch.optim.SGD(net.parameters(), lr=0.01)
    animator = d2l.Animator(xlabel='epoch', ylabel='loss', yscale='log',
                            xlim=[1, num_epochs], ylim=[1e-3, 1e2],
                            legend=['train', 'test'])
    for epoch in range(num_epochs):
        d2l.train_epoch_ch3(net, train_iter, loss, trainer)
        if epoch == 0 or (epoch + 1) % 20 == 0:
            animator.add(epoch + 1, (evaluate_loss(net, train_iter, loss),
                                     evaluate_loss(net, test_iter, loss)))
    print('weight:', net[0].weight.data.numpy())
```

这里分别用三阶多项式、线性函数和高阶多项式函数来拟合：
```python
#三阶多项式
# 从多项式特征中选择前4个维度，即1,x,x^2/2!,x^3/3!
train(poly_features[:n_train, :4], poly_features[n_train:, :4],
      labels[:n_train], labels[n_train:])
      
#线性函数
# 从多项式特征中选择前2个维度，即1和x
train(poly_features[:n_train, :2], poly_features[n_train:, :2],
      labels[:n_train], labels[n_train:])
      
# 从多项式特征中选取所有维度
train(poly_features[:n_train, :], poly_features[n_train:, :],
      labels[:n_train], labels[n_train:], num_epochs=1500)
```
观察图像可发现正常拟合、欠拟合和过拟合的模式

## 4.5 权重衰减
多项式对多变量数据的自然扩展称为**单项式 (monomials)**, 也可以说是变量幂的乘积。当最高幂 $d$ 增大时，单项式会迅速增加
> 例如 $x_1 x_2^2$ 的次数是 $3$

**权重衰减(weight decay)** 是正则化技术之一，通常称为 $L_2$ 正则化。用权重向量的范数度量其复杂性，并加入到损失函数中，可以约束权重大小：
$$
L(\mathbf{w},b)+\frac{\lambda}{2}\|\mathbf{w}\|^2
$$
其中 $L (\textbf{w}, b)$ 是平方损失：
$$
L(\mathbf{w},b)=\frac{1}{n}\sum_{i=1}^n\frac{1}{2}\left(\mathbf{w}^\top\mathbf{x}^{(i)}+b-y^{(i)}\right)^2
$$
$\lambda$ 控制了正则化的惩罚强度

$L_1$ 范数和 $L_2$ 范数对权重的约束不同：
* $L_1$ 范数将权重集中在小部分特征上，其他权重设置为 0，实现**特征选择 (feature selection)**
* $L_2$ 范数限制向量中的大分量，选择一个分量较均匀的向量

权重更新的数学表达式如下
$$
\mathbf{w}\leftarrow(1-\eta\lambda)\mathbf{w}-\frac{\eta}{|\mathcal{B}|}\sum_{i\in\mathcal{B}}\mathbf{x}^{(i)}\left(\mathbf{w}^\top\mathbf{x}^{(i)}+b-y^{(i)}\right)
$$
此处 $(1 - \eta \lambda)$ 因子试图将 $\textbf{w}$ 减小到 0，因此实现权重的衰减。通常，不对 $b$ 进行正则化

### 4.5.1 高维线性回归

以高维线性回归来演示权重衰减。生成数据公式：
$$
y=0.05+\sum_{i=1}^d0.01x_i+\epsilon\mathrm{~where~}\epsilon\sim\mathcal{N}(0,0.01^2).
$$
代码：
```python
import torch
from torch import nn
from d2l import torch as d2l

#生成数据集
n_train, n_test, num_inputs, batch_size = 20, 100, 200, 5
true_w, true_b = torch.ones((num_inputs, 1)) * 0.01, 0.05
train_data = d2l.synthetic_data(true_w, true_b, n_train)
train_iter = d2l.load_array(train_data, batch_size)
test_data = d2l.synthetic_data(true_w, true_b, n_test)
test_iter = d2l.load_array(test_data, batch_size, is_train=False)
```
初始化模型参数：
```python
def init_params():
    w = torch.normal(0, 1, size=(num_inputs, 1), requires_grad=True)
    b = torch.zeros(1, requires_grad=True)
    return [w, b]
```

定义 $L_2$ 范数惩罚：
```python
def l2_penalty(w):
    return torch.sum(w.pow(2)) / 2
```

定义训练代码：
```python
def train(lambd):
    w, b = init_params()
    net, loss = lambda X: d2l.linreg(X, w, b), d2l.squared_loss #定义网络和损失
    num_epochs, lr = 100, 0.003 #训练超参数
    animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log',
                            xlim=[5, num_epochs], legend=['train', 'test'])
    for epoch in range(num_epochs):
        for X, y in train_iter:
            # 增加了L2范数惩罚项，
            # 广播机制使l2_penalty(w)成为一个长度为batch_size的向量
            l = loss(net(X), y) + lambd * l2_penalty(w)
            l.sum().backward()
            d2l.sgd([w, b], lr, batch_size)
        if (epoch + 1) % 5 == 0:
            animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss),
                                     d2l.evaluate_loss(net, test_iter, loss)))
    print('w的L2范数是：', torch.norm(w).item())
```

在不使用正则化的情况下直接训练，即 $\lambda = 0$：
```python
train(lambd=0)
```
图像表明训练误差下降的过程中测试误差没有下降，出现了严重过拟合
![[Pasted image 20250319104942.png]]

使用权重衰减：
```python
train(lambd=3)
```
注意到测试误差和训练误差都在下降，正则化有效
![[Pasted image 20250319105059.png]]
### 4.5.3 简洁实现
`torch` 在优化器中提供了 `weight_decay` 参数，可以指定权重衰减：
```python
def train_concise(wd): #接受一个lambda值
    net = nn.Sequential(nn.Linear(num_inputs, 1))
    for param in net.parameters():
        param.data.normal_()
    loss = nn.MSELoss(reduction='none')
    num_epochs, lr = 100, 0.003
    # 偏置参数没有衰减
    trainer = torch.optim.SGD([
        {"params":net[0].weight,'weight_decay': wd}, #指定权重衰减的lambda值
        {"params":net[0].bias}], 
        lr=lr)
    animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log',
                            xlim=[5, num_epochs], legend=['train', 'test'])
    for epoch in range(num_epochs):
        for X, y in train_iter:
            trainer.zero_grad()
            l = loss(net(X), y)
            l.mean().backward()
            trainer.step()
        if (epoch + 1) % 5 == 0:
            animator.add(epoch + 1,
                         (d2l.evaluate_loss(net, train_iter, loss),
                          d2l.evaluate_loss(net, test_iter, loss)))
    print('w的L2范数：', net[0].weight.norm().item())
```

## 4.6 暂退法 (Dropout)
### 4.6.1 重新审视过拟合
深度神经网络的参数十分庞大，以至于非常容易过拟合。以随机分配标签的十个数据集训练，训练精度可接近 100%，而测试精度仅 90%，泛化误差 (训练与测试表现差异) 为 90%

### 4.6.2-4.6.3 扰动的稳健性和实践中的 dropout
优秀的模型应当对噪声和扰动具有稳健性。例如，对输入图像添加噪声，模型的输出保持不变，这在数学上可看做对 $\epsilon \sim \mathcal {N}(0,\sigma^2)$，$\textbf{x}' = \textbf{x} + \epsilon$，有：
$$
E(\textbf{x}') = \textbf{x}
$$
用暂退法，对每层的神经元，按 $p$ 的概率随机丢弃其激活值 $h$，我们有：
$$
h^{\prime}=
\begin{cases}
0 & \text{概率为}p \\
\frac{h}{1-p} & \text{其他情况} & & 
\end{cases}
$$
且保证 $E (h') = h$

一般来说，测试时不使用 dropout；然而，有些测试需要用 dropout 估计神经网络的不确定性

### 4.6.4 从零开始实现 

从均匀分布 $U[0, 1]$ 中抽取样本，数量与神经网络维度一致，则保留样本对应大于 $p$ 的节点，丢弃剩余节点，即可实现 dropout：
```python
import torch
from torch import nn
from d2l import torch as d2l

#定义dropout层
def dropout_layer(X, dropout): # dropout 表示丢弃率
    assert 0 <= dropout <= 1
    # 在本情况中，所有元素都被丢弃
    if dropout == 1:
        return torch.zeros_like(X)
    # 在本情况中，所有元素都被保留
    if dropout == 0:
        return X
    mask = (torch.rand(X.shape) > dropout).float() # 一个bool向量, 转换为float
    return mask * X / (1.0 - dropout) # 输出结果会翻一定倍数
```
其中 `torch.rand()` 生成了一个 $[0, 1)$ 均匀分布，其大小为 `X.shape`

测试 dropout 函数：
```python
#函数测试
X= torch.arange(16, dtype = torch.float32).reshape((2, 8))
print(X)
print(dropout_layer(X, 0.))
print(dropout_layer(X, 0.5))
print(dropout_layer(X, 1.))
```

下面实现有 dropout 的感知机，首先定义模型参数：
```python
#模型参数定义
num_inputs, num_outputs, num_hiddens1, num_hiddens2 = 784, 10, 256, 256
```
定义模型：
```python
dropout1, dropout2 = 0.2, 0.5

class Net(nn.Module):
    def __init__(self, num_inputs, num_outputs, num_hiddens1, num_hiddens2,
                 is_training = True):
        super(Net, self).__init__()
        self.num_inputs = num_inputs
        self.training = is_training
        self.lin1 = nn.Linear(num_inputs, num_hiddens1)
        self.lin2 = nn.Linear(num_hiddens1, num_hiddens2)
        self.lin3 = nn.Linear(num_hiddens2, num_outputs)
        self.relu = nn.ReLU()

    def forward(self, X):
        H1 = self.relu(self.lin1(X.reshape((-1, self.num_inputs))))
        # 只有在训练模型时才使用dropout
        if self.training == True:
            # 在第一个全连接层之后添加一个dropout层
            H1 = dropout_layer(H1, dropout1)
        H2 = self.relu(self.lin2(H1))
        if self.training == True:
            # 在第二个全连接层之后添加一个dropout层
            H2 = dropout_layer(H2, dropout2)
        out = self.lin3(H2)
        return out

net = Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2)
```
这里与之前不同，通过继承 `nn.Module` 类来实现神经网络

对模型进行训练和测试：
```python
#训练和测试模型
num_epochs, lr, batch_size = 10, 0.5, 256
loss = nn.CrossEntropyLoss(reduction='none')
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
trainer = torch.optim.SGD(net.parameters(), lr=lr)
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)
```

### 4.6.5 简洁实现
使用 `torch` 的 API，只需要在全连接层后添加 Dropout 层即可：
```python
#添加dropout层
net = nn.Sequential(nn.Flatten(),
        nn.Linear(784, 256),
        nn.ReLU(),
        # 在第一个全连接层之后添加一个dropout层
        nn.Dropout(dropout1),
        nn.Linear(256, 256),
        nn.ReLU(),
        # 在第二个全连接层之后添加一个dropout层
        nn.Dropout(dropout2),
        nn.Linear(256, 10))

def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, std=0.01)

net.apply(init_weights);
```

训练和测试：
```python
trainer = torch.optim.SGD(net.parameters(), lr=lr)
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)
```

## 4.7 前向传播、反向传播和计算图

### 4.7.1 前向传播
**前向传播 (forward propagation)** 指的是按顺序 (从输入层到输出层) 计算和存储神经网络中每层的结果

以单隐藏层神经网络为例。假设输入样本 $\textbf{x} \in \mathbb{R}^d$，隐藏层不含偏置：
$$
\mathbf{z}=\mathbf{W}^{(1)}\mathbf{x}
$$
得到中间变量 $\textbf{z}$，其中 $\textbf{W}^{(1)} \in \mathbb{R}^{h \times d}$。将中间变量通过激活函数，得长度为 $h$ 的隐藏激活向量：
$$
\mathbf{h}=\phi(\mathbf{z})
$$
其中隐藏变量 $\textbf{h}$ 也是中间变量。假设输出层权重 $\textbf{W}^{(2)} \in \mathbb{R}^{q \times h}$，得到输出层变量：
$$
\mathbf{o}=\mathbf{W}^{(2)}\mathbf{h}
$$
这是一个长度为 $q$ 的向量

设损失函数 $l$，样本标签为 $y$，则单个数据样本损失：
$$
L=l(\mathbf{o},y)
$$
给定超参数 $\lambda$，$L_2$ 正则化项：
$$
s=\frac{\lambda}{2}\left(\|\mathbf{W}^{(1)}\|_F^2+\|\mathbf{W}^{(2)}\|_F^2\right)
$$
其中矩阵的 Frobenius 范数是将矩阵展平为向量得到的 $L_2$ 范数。最后，模型在给定数据样本上的正则化损失：
$$
J = L + s
$$
称 $J$ 为**目标函数 (objective function)**

### 4.7.2 前向传播计算图
下图是与上述简单网络相对应的计算图,  其中正方形表示变量, 圆圈表示操作符。左下角表示输入, 右上角表示输出。注意显示数据流的箭头方向主要是向右和向上的：
![[Pasted image 20250322144124.png]]

### 4.7.3 反向传播
**反向传播 (backward propagation)** 指的是计算神经网络参数梯度的方法。反向传播的核心在于求偏导数，特别注意偏导数在复合函数中的求法

设函数 $Y = f (X), Z = g (Y)$，则 $Z$ 对 $X$ 的偏导数：
$$
\frac{\partial{Z}}{\partial{X}}=\mathrm{prod}\left(\frac{\partial{Z}}{\partial{Y}},\frac{\partial{Y}}{\partial{X}}\right).
$$
这里的 $\text{Prod}$ 运算符表示执行必要操作后参数相乘，这是针对矩阵求导的写法

在上面的计算图中，我们的目的是求 $\partial{J} / \partial{\textbf{W}}^{(1)}$ 和 $\partial{J} /\partial{\textbf{W}}^{(2)}$。我们应用链式法则，按反向的顺序依次求导，首先：
$$
\frac{\partial J}{\partial L}=1\mathrm{~and~}\frac{\partial J}{\partial s}=1
$$
得到 $L$ 和 $s$ 的梯度。接着，求关于输出层变量 $\textbf{o}$ 的梯度：
$$
\frac{\partial J}{\partial\mathbf{o}}=\mathrm{prod}\left(\frac{\partial J}{\partial L},\frac{\partial L}{\partial\mathbf{o}}\right)=\frac{\partial L}{\partial\mathbf{o}}\in\mathbb{R}^q
$$
接着，计算正则化项关于两个参数的梯度：
$$
\frac{\partial s}{\partial\mathbf{W}^{(1)}}=\lambda\mathbf{W}^{(1)}\mathrm{~and~}\frac{\partial s}{\partial\mathbf{W}^{(2)}}=\lambda\mathbf{W}^{(2)}
$$
根据链式法则，我们可计算 $J$ 关于这个 $\textbf{W}^{(2)}$ 的梯度了：
$$
\frac{\partial J}{\partial\mathbf{W}^{(2)}}=\mathrm{prod}\left(\frac{\partial J}{\partial\mathbf{o}},\frac{\partial\mathbf{o}}{\partial\mathbf{W}^{(2)}}\right)+\mathrm{prod}\left(\frac{\partial J}{\partial s},\frac{\partial s}{\partial\mathbf{W}^{(2)}}\right)=\frac{\partial J}{\partial\mathbf{o}}\mathbf{h}^\top+\lambda\mathbf{W}^{(2)}
$$
继续反向传播，我们得到 $J$ 关于 $\textbf{h}$ 的梯度：
$$
\frac{\partial J}{\partial\mathbf{h}}=\mathrm{prod}\left(\frac{\partial J}{\partial\mathbf{o}},\frac{\partial\mathbf{o}}{\partial\mathbf{h}}\right)=\mathbf{W}^{(2)\top}\frac{\partial J}{\partial\mathbf{o}}.
$$
由于激活函数 $\varPhi$ 按元素计算，计算中间变量 $\textbf{z}$ 的梯度需要用按元素乘法运算符：
$$
\frac{\partial J}{\partial\mathbf{z}}=\mathrm{prod}\left(\frac{\partial J}{\partial\mathbf{h}},\frac{\partial\mathbf{h}}{\partial\mathbf{z}}\right)=\frac{\partial J}{\partial\mathbf{h}}\odot\phi^{\prime}\left(\mathbf{z}\right)
$$
最后，我们得到最接近输入层的模型参数的梯度 $\textbf{W}^{(1)}$，由链式法则：
$$
\frac{\partial J}{\partial\mathbf{W}^{(1)}}=\mathrm{prod}\left(\frac{\partial J}{\partial\mathbf{z}},\frac{\partial\mathbf{z}}{\partial\mathbf{W}^{(1)}}\right)+\mathrm{prod}\left(\frac{\partial J}{\partial s},\frac{\partial s}{\partial\mathbf{W}^{(1)}}\right)=\frac{\partial J}{\partial\mathbf{z}}\mathbf{x}^\top+\lambda\mathbf{W}^{(1)}.
$$

### 4.7.4 训练神经网络
训练神经网络的过程中，前向传播和反向传播相互依赖：
* 计算正则项取决于 $\textbf{W}$ 的当前值，来自优化算法根据最近的反向传播得到
* 反向传播计算梯度，取决于前向传播给出的隐藏变量 $\textbf{h}$ 的当前值
> 反向传播重复利用前向传播中存储的中间值,以避免重复计算

训练神经网络需要大量的内存 (显存) 保留中间值，因此大批量训练更深的神经网络容易内存不足

## 4.8 数值稳定性和模型初始化

### 4.8.1 梯度消失和梯度爆炸
考虑一个 $L$ 层、输入 $\textbf{x}$ 和输出 $\textbf{o}$ 的深层网络，每一层 $l$ 的变换 $f_1$，参数 $\textbf{W}^{(l)}$，隐藏变量 $\textbf{h}^{(l)}$，则网络可表示为：
$$
\partial_{\mathbf{W}^{(l)}}\mathbf{o}=\underbrace{\partial_{\mathbf{h}^{(L-1)}}\mathbf{h}^{(L)}}_{\mathbf{M}^{(L)}\overset{\mathrm{def}}{\operatorname*{\operatorname*{=}}}}\cdot\ldots\cdot\underbrace{\partial_{\mathbf{h}^{(l)}}\mathbf{h}^{(l+1)}}_{\mathbf{M}^{(l+1)}\overset{\mathrm{def}}{\operatorname*{\operatorname*{=}}}}\underbrace{\partial_{\mathbf{W}^{(l)}}\mathbf{h}^{(l)}}_{\mathbf{v}^{(l)}\overset{\mathrm{def}}{\operatorname*{\operatorname*{=}}}}
$$
换言之，这个梯度是 $L - l$ 个矩阵 $\textbf{M}^{(L)} \dots \textbf{M}^{(l+1)}$ 与梯度 $\textbf{v}^{l}$ 的乘积，我们容易受到数值下溢出的影响 (表示精度不足)。若将它们转换到对数尺度上，又可能导致乘积很大或很小的问题

我们可能面临一些问题。要么**是梯度爆炸 (gradient exploding)** 问题：参数更新过大, 破坏了模型的稳定收敛；要么是**梯度消失 (gradient vanishing)** 问题：参数更新过小, 在每次更新时几乎不会移动, 导致模型无法学习

sigmoid 函数容易出现梯度问题。注意它的函数曲线和梯度曲线：
![[Pasted image 20250322150845.png]]
在输入很大或是很小时，梯度都接近 0，导致梯度的消失。现在从业者大多使用 ReLU 函数来解决此问题

大量矩阵相乘很可能导致梯度爆炸，这是由于初始化导致的，我们无法让梯度下降优化器收敛

***
考虑神经网络的对称性问题。假设一个简单多层感知机，含一个隐藏层和两个隐藏单元。在这种情况下，我们可对第一层权重 $\textbf{W}^{(1)}$ 进行重排列，并且对输出层权重重排列，则我们得到的函数一样，两个隐藏单元无差异，这里展示了对称性问题

假设输出为一个标量，且初始化两个权重都为 $c$。则在反向传播时，计算得到的梯度都一样，权重更新后也一样，对称性不会被打破，无法实现网络的表达能力

解决方法包括随机初始化和 Dropout，需注意 SGD 不会打破对称性

### 4.8.2 参数初始化

参数初始化的方法有：
* 默认初始化。用正态分布初始化权重，这是 API 的默认行为，在中等难度问题上有效
* **Xavier 初始化**。为了控制每层前向传播和反向传播的方差尽可能保持不变，权重初始化值域为
$$
U\left(-\sqrt{\frac{6}{n_{\mathbf{in}}+n_{\mathbf{out}}}},\sqrt{\frac{6}{n_{\mathbf{in}}+n_{\mathbf{out}}}}\right)
$$
其中 $n_{\text{in}}$ 和 $n_{\text{out}}$ 分别表示为输入维度和输出维度

> 原作者认为本节有许多可探索的方法，可适当阅读原始文献；忽略了 Xaiver 的推导

## 4.9 环境和分布偏移
机器学习的应用可能会在数据的分布发生改变时失败，甚至因为决策导致更严重的恶性循环

### 4.9.1 分布偏移的类型

假设来自分布 $p_S(\textbf{x}, y)$ 的训练数据和包含分布 $p_T (\textbf{x}, y)$ 的未标记样本，若没有关于两个分布 $p_S$ 和 $p_T$ 之间的假设，我们不可能实现一个有用的分类器。例如，对二元分类区分猫和狗，若之后的“猫”和“狗”的概念对调，而输入的特征 $p (\textbf{x})$ 分布没有改变，则无法区分这两种情况，即分布偏移

一种类型的分布偏移是**协变量偏移 (covariate shift)**，即输入分布随时间改变，但标签 $P (y | \textbf{x})$ 没有改变。举例是用真实的猫狗图像训练分类器，但测试集为卡通图像

**标签偏移 (lable shift)** 描述的问题与协变量偏移相反，假设 $P (y)$ 改变而 $P (\textbf{x} | y)$ 没有改变。当标签的定义改变时，发生**概念偏移(concept shift)**，例如单词语义的变化

### 4.9.2 分布偏移实例

一个例子是医学诊断。用血液指标构建分类器可以很容易区分病人与健康人，但是无法检测疾病，因为有很多的协变量影响患病者和健康者的血液指标，我们不清楚到底谁患病

当分布变化缓慢并且模型没有得到充分更新时,就会出现更微妙的情况**非平稳分布 (nonstationary distribution)**。例如 2009 年的模型不知道 iPad 诞生，无法推送广告

### 4.9.3 分布偏移纠正

**协变量偏移纠正**
考虑经典的损失：
$$
\operatorname*{minimize}_f\frac{1}{n}\sum_{i=1}^nl(f(\mathbf{x}_i),y_i),
$$
这被称为**经验风险 (empirical risk)**，是为了近似**真实风险 (true risk)**。从训练集上得到平均损失，也即真是分布 $p (\textbf{x}, y)$ 抽取所有数据的总体损失的期望：
$$
E_{p(\mathbf{x},y)}[l(f(\mathbf{x}),y)]=\int\int l(f(\mathbf{x}),y)p(\mathbf{x},y)\mathrm{~}d\mathbf{x}dy
$$
我们在实践中无法获取全体数据，经验风险的最小化即是近似地最小化真实风险

我们用 $\textbf{x}$ 估计 $y$，评估 $P (y | \textbf{x})$ 用到的是抽样的分布 $q (\textbf{x})$，而不是目标分布 $p(\textbf{x})$。通常假设 $p (y | \textbf{x}) = q (y | \textbf{x})$。若抽样分布不能代表真实分布，我们通过在真实风险的计算中用下面的等式纠正：
$$
\int\int l(f(\mathbf{x}),y)p(y\mid\mathbf{x})p(\mathbf{x})\mathrm{~}d\mathbf{x}dy=\int\int l(f(\mathbf{x}),y)q(y\mid\mathbf{x})q(\mathbf{x})\frac{p(\mathbf{x})}{q(\mathbf{x})}\mathrm{~}d\mathbf{x}dy
$$
换言之，我们需要根据数据来自正确分布与来自错误分布的概率之比, 来重新衡量每个数据样本的权重：
$$
\beta_i\overset{\mathrm{def}}{\operatorname*{\operatorname*{=}}}\frac{p(\mathbf{x}_i)}{q(\mathbf{x}_i)}.
$$
将权重 $\beta_i$ 代入每个观测对中，我们可用“加权经验风险最小化”训练模型：
$$
\operatorname*{minimize}_f\frac{1}{n}\sum_{i=1}^n\beta_il(f(\mathbf{x}_i),y_i).
$$
由于不知道这个比率, 我们需要估计它。
> 权重 $\beta_i$ 的大小衡量 $x_i$ 在两个分布中出现概率的大小，若 $p (x_i) > q (x_i)$，则说明 $x_i$ 在真实分布中更容易出现，权重 $\beta_i$ 应更大

我们不知道 $p (x)$ 和 $q(x)$，需要用**对数几率回归 (logistic regression)** 来估计概率密度比。现在将目标分布标记为 $z=1$，源分布 (训练分布) 标记为 $z=-1$，则混合数据集中的概率：
$$
P(z=1\mid\mathbf{x})=\frac{p(\mathbf{x})}{p(\mathbf{x})+q(\mathbf{x})}\text{ and hence }\frac{P(z=1\mid\mathbf{x})}{P(z=-1\mid\mathbf{x})}=\frac{p(\mathbf{x})}{q(\mathbf{x})}.
$$
若用对数几率回归，则 $P(z=1\mid\mathbf{x})=\frac{1}{1+\exp(-h(\mathbf{x}))}$，有：
$$
\beta_i=\frac{1/(1+\exp(-h(\mathbf{x}_i)))}{\exp(-h(\mathbf{x}_i))/(1+\exp(-h(\mathbf{x}_i)))}=\exp(h(\mathbf{x}_i))
$$
其中 $h$ 是一个参数化函数

为了获得这个估计，我们需要：
* 区分来自两个分布的数据
* 对经验风险加权，进行加权经验风险最小化
设我们的训练集 $\{ (\textbf{x}_1, y_1), \dots, (\textbf{x}_n, y_n) \}$，测试集 $\{ \textbf{u}_1, \dots, \textbf{u}_m \}$，分别来自两个分布，则算法：
1. 生成二分类数据集 $\{(\mathbf{x}_1,-1),\ldots,(\mathbf{x}_n,-1),(\mathbf{u}_1,1),\ldots,(\mathbf{u}_m,1)\}$
2. 用对数几率回归，训练一个二元分类器，得到函数 $h$
3. 用 $\beta_i=\exp(h(\mathbf{x}_i))$ 或者更好的 $\beta_i=\min(\exp(h(\mathbf{x}_i)),c)$，$c$ 为常量对训练数据加权
4. 用权重 $\beta_i$ 训练模型
这个算法依赖于假设：目标分布 (例如, 测试分布) 中的每个数据样本在训练时出现的概率非零。如果我们找到 p (x) > 0 但 q (x) = 0 的点, 那么相应的重要性权重会是无穷大

**标签偏移纠正**
设处理 $k$ 个类的分类任务，$q, p$ 分别表示源分布和目标分布。假设标签分布随时间变化，即 $q(y) \not = p(y)$，但类别的条件分布不变，即 $q(\mathbf{x}\mid y)=p(\mathbf{x}\mid y)$。我们用上面提到的恒等式对错误的 $q (y)$ 更正：
$$
\int\int l(f(\mathbf{x}),y)p(\mathbf{x}\mid y)p(y)\mathrm{~}d\mathbf{x}dy=\int\int l(f(\mathbf{x}),y)q(\mathbf{x}\mid y)q(y)\frac{p(y)}{q(y)}\mathrm{~}d\mathbf{x}dy.
$$
这里，重要性权重对应标签似然比：
$$
\beta_i\overset{\mathrm{def}}{\operatorname*{\operatorname*{=}}}\frac{p(y_i)}{q(y_i)}.
$$
为了估计标签分布，首先采用性能相当好的现成的分类器 (通常基于训练数据进行训练), 并使用验证集 (也来自训练分布) 计算其混淆矩阵 $\textbf{C}_{k \times k}$，$c_{ij}$ 表示真实标签为 $i$，预测标签为 $j$ 的比率

用测试集的平均输出 $\mu (\hat{\textbf{y}}) \in  \mathbb{R}^k$ 来估计测试集标签分布。若标签偏移假设成立，我们可通过求解一个简单的线性系统估计测试集标签分布：
$$
\mathbf{C}p(\mathbf{y})=\mu(\hat{\mathbf{y}})
$$
若分类足够准确，且目标数据值包含我们见过的类别，此时混淆矩阵 $\textbf{C}$ 可逆，进而得到：
$$
p(y)=C^{-1}\mu(\hat{y}).
$$
有了 $p (y)$ 的估计，我们很容易计算权重 $\beta_i$ 了

**概念偏移纠正**
概念偏移纠正很难通过原则性方式解决，我们只能从零开始收集标签和训练。不过，我们可以使用同一个网络，只更新权重而不是重新训练

### 4.9.4 学习问题的分类法

**批量学习 (batch learning)** 通过一组训练特征和标签训练 $f (\textbf{x})$，然后对来自同一分布的新数据进行评分。当模型部署后，它们几乎不再更新

**在线学习 (online learning)** 会学习新的预测结果，不断改进模型：
$$
\mathrm{model~}f_t\longrightarrow\mathrm{data~}\mathbf{x}_t\longrightarrow\mathrm{estimate~}f_t(\mathbf{x}_t)\longrightarrow\text{observation }y_t\longrightarrow\mathrm{loss~}l(y_t,f_t(\mathbf{x}_t))\longrightarrow\mathrm{model~}f_{t\boldsymbol{+}1}
$$
它的一个特例是**老虎机(bandits)**，此时我们可采取的更新行动是有限的

在很多情况下, 环境会记住我们所做的事。不一定是以一种对抗的方式, 但它会记住, 而且它的反应将取决于之前发生的事情。这种情况下, PID  (比例—积分—微分) 控制器算法是一个流行的选择

**强化学习 (reinforcement learning)** 强调如何基于环境行动，以获得最大化的预期收益，例如自动驾驶

### 4.9.5 机器学习中的公平、责任和透明度

举个例子: 将图像错误地分到某一类别可能被视为种族歧视, 而错误地分到另一个类别是无害的, 那么我们可能需要相应地调整我们的阈值, 在设计决策方式时考虑到这些社会价值

通常, 在建模纠正过程中, 模型的预测与训练数据耦合的各种机制都没有得到解释, 研究人员称之为“失控反馈循环”的现象

## 4.10 实战 Kaggle 比赛：预测房价

本节使用亚利桑那州埃姆斯市房价数据集

### 4.10.1 下载和缓存数据集

这里实现一些函数用于下载数据集，数据集存放在一个字典 `DATA_HUB` 中：
```python
import hashlib
import os
import tarfile
import zipfile
import requests

DATA_HUB = dict() # 数据集名称-数据集映射
DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/' # 数据下载url
```

函数 `download` 用于下载数据集，并缓存到 `../data` 目录中，返回下载文件名称：
```python
def download(name, cache_dir=os.path.join('..', 'data')):
    """下载一个DATA_HUB中的文件，返回本地文件名"""
    assert name in DATA_HUB, f"{name} 不存在于 {DATA_HUB}"
    url, sha1_hash = DATA_HUB[name]
    os.makedirs(cache_dir, exist_ok=True)
    fname = os.path.join(cache_dir, url.split('/')[-1])
    if os.path.exists(fname):
        sha1 = hashlib.sha1()
        with open(fname, 'rb') as f:
            while True:
                data = f.read(1048576)
                if not data:
                    break
                sha1.update(data)
        if sha1.hexdigest() == sha1_hash:
            return fname  # 命中缓存
    print(f'正在从{url}下载{fname}...')
    r = requests.get(url, stream=True, verify=True)
    with open(fname, 'wb') as f:
        f.write(r.content)
    return fname
```
另外的两个函数中，一个将下载并解压缩一个zip或tar文件，另一个是将本书中使用的所有数据集从 `DATA_HUB` 下载到缓存目录中：
```python
def download_extract(name, folder=None):
    """下载并解压zip/tar文件"""
    fname = download(name)
    base_dir = os.path.dirname(fname)
    data_dir, ext = os.path.splitext(fname)
    if ext == '.zip':
        fp = zipfile.ZipFile(fname, 'r')
    elif ext in ('.tar', '.gz'):
        fp = tarfile.open(fname, 'r')
    else:
        assert False, '只有zip/tar文件可以被解压缩'
    fp.extractall(base_dir)
    return os.path.join(base_dir, folder) if folder else data_dir

def download_all():  #@save
    """下载DATA_HUB中的所有文件"""
    for name in DATA_HUB:
        download(name)
```

### 4.10.2 Kaggle
[Kaggle 网址]([Kaggle: Your Machine Learning and Data Science Community](https://www.kaggle.com/))。在 Kaggle 网站中，进入房价预测比赛，'Data'选项卡提供了数据集，在[网站](https://www.kaggle.com/c/house‐prices‐advanced‐regression‐techniques)提交预测，并查看排名

### 4.10.3 访问和读取数据集

处理数据有一些值得注意的地方：
* 不同的数据类型不同，可能包括 `int`、`float` 或标签变量
* 只有训练集中有房价，测试集中没有；只有官方测试集包含模型评估
因此，我们需要正确处理数据，并且在训练集中划分验证集

导入 `pandas` 包：
```python
import numpy as np
import pandas as pd
import torch
from torch import nn
from d2l import torch as d2l
```
然后，我们可用之前定义的函数获取数据集位置
```python
DATA_HUB['kaggle_house_train'] = (  
    DATA_URL + 'kaggle_house_pred_train.csv',
    '585e9cc93e70b39160e7921475f9bcd7d31219ce')

DATA_HUB['kaggle_house_test'] = (  
    DATA_URL + 'kaggle_house_pred_test.csv',
    'fa19780a7b011d9b009e8bff8e99922a8ee2eb90')
```
用 `pandas` 读取数据集：
```python
# 读取数据集
train_data = pd.read_csv(download('kaggle_house_train'))
test_data = pd.read_csv(download('kaggle_house_test'))
print(train_data.shape)
print(test_data.shape)
print(train_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]]) # 查看前4个和最后两个特征以及房价标签
```
注意到第一个特征是序号列，我们将它删除：
```python
all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))
```
其中 `pd.concat` 将两个 `pandas` 中的数据对象连接起来，其用法：
```python
pd.concat(objs, axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, sort=False, copy=True)
```
其中：
- **`objs`**：要连接的对象列表，可以是多个 Series 或 DataFrame。
- **`axis`**：指定连接的轴，`axis=0` 表示沿着行的方向连接（默认值），`axis=1` 表示沿着列的方向连接。
- **`join`**：
    - `'outer'`：取并集，保留所有索引（默认值）。
    - `'inner'`：取交集，只保留所有对象共有的索引。
- **`ignore_index`**：
    - `False`：保留原始索引。
    - `True`：忽略原始索引，重新生成一个整数索引。
- **`keys`**：为每个对象指定一个键值，用于在结果中创建多级索引。
- **`levels`**：为多级索引指定级别。
- **`names`**：为多级索引的级别指定名称。
- **`verify_integrity`**：是否检查结果索引的唯一性。
- **`sort`**：是否对结果索引进行排序。
- **`copy`**：是否复制数据。
这就像操作 `SQL` 语句

### 4.10.4 数据预处理
我们需要将所有的数据放缩到同一个尺度上：
$$
x' \leftarrow \frac{x - \mu}{\sigma}
$$
其中 $\mu$ 和 $\sigma$ 分别是样本均值和标准差。标准化后，样本的均值为 0，标准差为 $\sigma$

在代码中实现：
```python
# 若无法获得测试数据，则可根据训练数据计算均值和标准差
numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index
all_features[numeric_features] = all_features[numeric_features].apply(
    lambda x: (x - x.mean()) / (x.std()))
# 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0
all_features[numeric_features] = all_features[numeric_features].fillna(0)
```
> 实际上，可通过 `sklearn` 的标准化器 `Standscaler` 来实现标准化

对于离散的标签值，用独热编码替换：
```python
# “Dummy_na=True”将“na”（缺失值）视为有效的特征值，并为其创建指示符特征
all_features = pd.get_dummies(all_features, dummy_na=True)
all_features.shape
```
独热编码后，特征数量大大增加了。用 `values` 属性可从 `pandas` 中提取 `Numpy` 格式：
```python
n_train = train_data.shape[0]
train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float32)
test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float32)
train_labels = torch.tensor(
    train_data.SalePrice.values.reshape(-1, 1),  dtype=torch.float32) # 直接将列名作为属性
```
### 4.10.5 训练
首先，我们训练一个带有损失平方的线性模型。它的意义在于：
* 查看数据是否有意义。若模型结果近似随机猜测，可能是数据有误或处理有误
* 作为**基线 (baseline)** 模型与后续模型比较
```python
# 实现线性回归模型
loss = nn.MSELoss()
in_features = train_features.shape[1]

def get_net():
    net = nn.Sequential(nn.Linear(in_features,1))
    return net
```
事实上，我们关心的是相对误差 $\frac{y - \hat y}{y}$ 而不是绝对误差 $y - \hat y$。这里使用预测价格的对数误差来衡量差异：
$$
\sqrt{\frac{1}{n} \sum^n_{i=1} \left( \log y_i - \log \hat y_i \right)^2}
$$
```python
def log_rmse(net, features, labels):
    # 为了在取对数时进一步稳定该值，将小于1的值设置为1
    clipped_preds = torch.clamp(net(features), 1, float('inf'))
    rmse = torch.sqrt(loss(torch.log(clipped_preds),
                           torch.log(labels)))
    return rmse.item()
```
这里的 `torch.clamp(tensor, min, max)` 可将一个 `tensor` 中的数值限定在 $[\min, \max]$ 范围内

我们的训练器基于 `Adam` 优化器，它对初始学习率不那么敏感：
```python
def train(net, train_features, train_labels, test_features, test_labels,
          num_epochs, learning_rate, weight_decay, batch_size):
    train_ls, test_ls = [], []
    train_iter = d2l.load_array((train_features, train_labels), batch_size)
    # 这里使用的是Adam优化算法
    optimizer = torch.optim.Adam(net.parameters(),
                                 lr = learning_rate,
                                 weight_decay = weight_decay)
    for epoch in range(num_epochs):
        for X, y in train_iter:
            optimizer.zero_grad()
            l = loss(net(X), y)
            l.backward()
            optimizer.step()
        train_ls.append(log_rmse(net, train_features, train_labels))
        if test_labels is not None:
            test_ls.append(log_rmse(net, test_features, test_labels))
    return train_ls, test_ls
```

### 4.10.6 K 折交叉检验
K 折交叉检验可用于选择模型和超参数。这里定义一个获取 k 折交叉检验数据的函数，返回第 $i$ 个切片作为验证数据，其余作为训练数据：
```python
def get_k_fold_data(k, i, X, y):
    assert k > 1 # 确保k>1, 否则报错
    fold_size = X.shape[0] // k # 整除
    X_train, y_train = None, None # 初始化训练集和验证集
    for j in range(k):
        idx = slice(j * fold_size, (j + 1) * fold_size) # 计算当前折的索引范围
        X_part, y_part = X[idx, :], y[idx]
        if j == i: # 当前折就是第i折, 即验证集
            X_valid, y_valid = X_part, y_part
        elif X_train is None: # 训练集尚未初始化, 添加到训练集
            X_train, y_train = X_part, y_part
        else: # 拼接到训练集
            X_train = torch.cat([X_train, X_part], 0)
            y_train = torch.cat([y_train, y_part], 0)
    return X_train, y_train, X_valid, y_valid
```
当我们在K折交叉验证中训练K次后，返回训练和验证误差的平均值：
```python
def k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay,
           batch_size):
    train_l_sum, valid_l_sum = 0, 0
    for i in range(k):
        data = get_k_fold_data(k, i, X_train, y_train) # 获取数据
        net = get_net() # 获取网络
        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate, weight_decay, batch_size) # 对data解包, 因为返回两对值
        train_l_sum += train_ls[-1]
        valid_l_sum += valid_ls[-1]
        if i == 0: # 对第一折的训练和验证损失曲线进行可视化
            d2l.plot(list(range(1, num_epochs + 1)), [train_ls, valid_ls],
                     xlabel='epoch', ylabel='rmse', xlim=[1, num_epochs],
                     legend=['train', 'valid'], yscale='log')
        print(f'折{i + 1}，训练log rmse{float(train_ls[-1]):f}, '
              f'验证log rmse{float(valid_ls[-1]):f}')
    return train_l_sum / k, valid_l_sum / k
```
> 交叉检验在大数据集下并不是最优选择

### 4.10.7 模型选择
用 $K$ 折交叉检验训练模型：
```python
# 模型训练
k, num_epochs, lr, weight_decay, batch_size = 5, 100, 5, 0, 64
train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr,
                          weight_decay, batch_size)
print(f'{k}-折验证: 平均训练log rmse: {float(train_l):f}, '
      f'平均验证log rmse: {float(valid_l):f}')
```
注意，有时一组超参数的训练误差可能非常低，但K折交叉验证的误差要高得多，这表明模型过拟合了

### 4.10.8 提交 Kaggle 预测
当我们用交叉检验选择好合适的超参数后，可用所有的数据训练模型，然后保存 csv 数据上传到 Kaggle：
```python
def train_and_pred(train_features, test_features, train_labels, test_data,
                   num_epochs, lr, weight_decay, batch_size):
    net = get_net()
    train_ls, _ = train(net, train_features, train_labels, None, None,
                        num_epochs, lr, weight_decay, batch_size)
    d2l.plot(np.arange(1, num_epochs + 1), [train_ls], xlabel='epoch',
             ylabel='log rmse', xlim=[1, num_epochs], yscale='log')
    print(f'训练log rmse：{float(train_ls[-1]):f}')
    # 将网络应用于测试集。
    preds = net(test_features).detach().numpy()
    # 将其重新格式化以导出到Kaggle
    test_data['SalePrice'] = pd.Series(preds.reshape(1, -1)[0])
    submission = pd.concat([test_data['Id'], test_data['SalePrice']], axis=1)
    submission.to_csv('submission.csv', index=False)
```
如果测试集上的预测与K倍交叉验证过程中的预测相似，那就是时候把它们上传到Kaggle了。下面的代码将生成一个名为 `submission.csv` 的文件：
```python
# 获取预测数据
train_and_pred(train_features, test_features, train_labels, test_data,
               num_epochs, lr, weight_decay, batch_size)
```

